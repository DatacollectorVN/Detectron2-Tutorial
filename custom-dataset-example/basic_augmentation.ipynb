{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import sys\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog # read in document to know how it work\n",
    "# https://detectron2.readthedocs.io/en/latest/modules/utils.html?highlight=Visualizer#detectron2.utils.visualizer.Visualizer\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from utils import get_chestxray_dicts\n",
    "import detectron2.data.transforms as T\n",
    "from detectron2.config import get_cfg\n",
    "# use default mapper \n",
    "from detectron2.data import DatasetMapper, build_detection_train_loader"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "ANNOTATIONS_CSV = \"annotation_small.csv\"\n",
    "DETECTRON2 = \"detectron2-tutorial-example\"\n",
    "IMG_DIR = os.path.join(DETECTRON2, \"imgs\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "df = pd.read_csv(os.path.join(DETECTRON2, ANNOTATIONS_CSV))\n",
    "class_name = df.class_name.unique().tolist()\n",
    "DatasetCatalog.register(\"my_dataset\", lambda : get_chestxray_dicts(df, class_name, IMG_DIR))\n",
    "MetadataCatalog.get(\"my_dataset\").set(thing_classes = class_name)\n",
    "\n",
    "cfg = get_cfg()\n",
    "cfg.DATASETS.TRAIN = (\"my_dataset\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate dataloader with augmenation (Resize(256, 256))"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "dataloader = build_detection_train_loader(cfg, mapper = DatasetMapper(cfg, is_train = True, augmentations = [T.Resize((256, 256))]),\n",
    "                                          total_batch_size = 5)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get samples from dataloader "
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "samples = iter(dataloader).__next__() # return list(dict()) with each dict() is Detectron2 format and len(samples) = total_batch_size\n",
    "print(f\"len(samples) = {len(samples)}\")\n",
    "print(f\"type(samples) = {type(samples)}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(samples) = 5\n",
      "type(samples) = <class 'list'>\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get sample in samples"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "print(f\"samples[0] = \\n{samples[0]}\") # return disct()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "samples[0] = \n",
      "{'image_id': 44, 'file_name': 'detectron2-tutorial-example/imgs/b0a52e18d443efb28d082f0ae8e7b893.jpg', 'height': 880, 'width': 927, 'image': tensor([[[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [121, 131, 141,  ...,  93,  77,  63],\n",
      "         [119, 131, 143,  ...,  91,  76,  63],\n",
      "         [120, 131, 139,  ...,  91,  77,  63]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [121, 131, 141,  ...,  93,  77,  63],\n",
      "         [119, 131, 143,  ...,  91,  76,  63],\n",
      "         [120, 131, 139,  ...,  91,  77,  63]],\n",
      "\n",
      "        [[  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         [  0,   0,   0,  ...,   0,   0,   0],\n",
      "         ...,\n",
      "         [121, 131, 141,  ...,  93,  77,  63],\n",
      "         [119, 131, 143,  ...,  91,  76,  63],\n",
      "         [120, 131, 139,  ...,  91,  77,  63]]], dtype=torch.uint8), 'instances': Instances(num_instances=5, image_height=256, image_width=256, fields=[gt_boxes: Boxes(tensor([[ 59.0982, 148.6545, 206.8436, 206.8364],\n",
      "        [125.9288,  76.5091, 161.5534, 121.3091],\n",
      "        [ 61.0313, 160.2909, 179.2276, 212.9454],\n",
      "        [122.8910,  74.1818, 159.8964, 122.7636],\n",
      "        [ 60.2028, 147.2000, 210.4337, 203.3455]])), gt_classes: tensor([1, 0, 1, 0, 1])])}\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "print(f\"len(samples[0]) = {len(samples[0])}\")\n",
    "print(f\"samples[0].keys() = {samples[0].keys()}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(samples[0]) = 6\n",
      "samples[0].keys() = dict_keys(['image_id', 'file_name', 'height', 'width', 'image', 'instances'])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get metadata of image in sample"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "print(f\"samples[0]['image'].shape = {samples[0]['image'].shape}\")\n",
    "print(f\"samples[0]['file_name'] = {samples[0]['file_name']}\")\n",
    "print(f\"samples[0]['image_id'] = {samples[0]['image_id']}\")\n",
    "print(f\"samples[0]['height'] = {samples[0]['height']}\")\n",
    "print(f\"samples[0]['width'] = {samples[0]['width']}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "samples[0]['image'].shape = torch.Size([3, 256, 256])\n",
      "samples[0]['file_name'] = detectron2-tutorial-example/imgs/b0a52e18d443efb28d082f0ae8e7b893.jpg\n",
      "samples[0]['image_id'] = 44\n",
      "samples[0]['height'] = 880\n",
      "samples[0]['width'] = 927\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get annotations of image in sample"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "print(f\"samples[0]['instances'] = {samples[0]['instances']}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "samples[0]['instances'] = Instances(num_instances=5, image_height=256, image_width=256, fields=[gt_boxes: Boxes(tensor([[ 59.0982, 148.6545, 206.8436, 206.8364],\n",
      "        [125.9288,  76.5091, 161.5534, 121.3091],\n",
      "        [ 61.0313, 160.2909, 179.2276, 212.9454],\n",
      "        [122.8910,  74.1818, 159.8964, 122.7636],\n",
      "        [ 60.2028, 147.2000, 210.4337, 203.3455]])), gt_classes: tensor([1, 0, 1, 0, 1])])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Get fileds in instances"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "samples[0]['instances']"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Instances(num_instances=5, image_height=256, image_width=256, fields=[gt_boxes: Boxes(tensor([[ 59.0982, 148.6545, 206.8436, 206.8364],\n",
       "        [125.9288,  76.5091, 161.5534, 121.3091],\n",
       "        [ 61.0313, 160.2909, 179.2276, 212.9454],\n",
       "        [122.8910,  74.1818, 159.8964, 122.7636],\n",
       "        [ 60.2028, 147.2000, 210.4337, 203.3455]])), gt_classes: tensor([1, 0, 1, 0, 1])])"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "samples[0]['instances'][:2]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Instances(num_instances=2, image_height=256, image_width=256, fields=[gt_boxes: Boxes(tensor([[ 59.0982, 148.6545, 206.8436, 206.8364],\n",
       "        [125.9288,  76.5091, 161.5534, 121.3091]])), gt_classes: tensor([1, 0])])"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "print(f\"samples[0]['instances']._image_size = {samples[0]['instances']._image_size}\") # H, W"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "samples[0]['instances']._image_size = (256, 256)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "print(f\"samples[0]['instances'].get('gt_boxes') = \\n{samples[0]['instances'].get('gt_boxes')}\")\n",
    "print()\n",
    "print(f\"samples[0]['instances'].get('gt_classes') = {samples[0]['instances'].get('gt_classes')}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "samples[0]['instances'].get('gt_boxes') = \n",
      "Boxes(tensor([[ 59.0982, 148.6545, 206.8436, 206.8364],\n",
      "        [125.9288,  76.5091, 161.5534, 121.3091],\n",
      "        [ 61.0313, 160.2909, 179.2276, 212.9454],\n",
      "        [122.8910,  74.1818, 159.8964, 122.7636],\n",
      "        [ 60.2028, 147.2000, 210.4337, 203.3455]]))\n",
      "\n",
      "samples[0]['instances'].get('gt_classes') = tensor([1, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "height, width = samples[0]['instances']._image_size\n",
    "print(f\"height = {height}\")\n",
    "print(f\"width = {width}\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "height = 256\n",
      "width = 256\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# compute are of each bbox\n",
    "samples[0]['instances'].get(\"gt_boxes\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Boxes(tensor([[148.2698,  55.9328, 175.2962,  92.8115],\n",
       "        [142.2639,  55.3181, 176.0469,  87.2797],\n",
       "        [146.7683,  57.1621, 174.1701,  79.9040],\n",
       "        [106.2287, 122.6218, 213.5836, 154.8908]]))"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "samples[0][\"instances\"].get(\"gt_boxes\").tensor"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[ 59.0982, 148.6545, 206.8436, 206.8364],\n",
       "        [125.9288,  76.5091, 161.5534, 121.3091],\n",
       "        [ 61.0313, 160.2909, 179.2276, 212.9454],\n",
       "        [122.8910,  74.1818, 159.8964, 122.7636],\n",
       "        [ 60.2028, 147.2000, 210.4337, 203.3455]])"
      ]
     },
     "metadata": {},
     "execution_count": 31
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "samples[0]['instances'].get(\"gt_classes\")"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 0, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.7.11",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.11 64-bit ('detectron2': conda)"
  },
  "interpreter": {
   "hash": "949420be4eb55280c8073c17b0b83e165e55c632164a785761e424e29c7bf4e3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}